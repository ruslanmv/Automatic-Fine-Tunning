{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06ce1c4-3d3d-4ad5-9893-27065c290b96",
   "metadata": {},
   "source": [
    "# ruslanmv/Automatic-Fine-Tunning\n",
    "## For SageMaker/ Google Colab\n",
    "\n",
    "In this notebook we are going to Fine Tune the Mixtral Model adapted to ai-medical-chatbot with more than 250k of records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f408f1b5-3d83-4697-83f4-bb1bf8dbf2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage: 0.7%\n",
      "Total Memory: 239.86 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil  # Install using `!pip install psutil` if needed\n",
    "def get_cpu_and_memory_info():\n",
    "    \"\"\"Retrieves CPU usage (percentage) and total memory (GB) information.\n",
    "    Returns:\n",
    "        dict: A dictionary containing CPU usage and total memory information.\n",
    "    \"\"\"\n",
    "    cpu_usage = psutil.cpu_percent(interval=1)  # Sample CPU usage every second\n",
    "    total_memory = psutil.virtual_memory().total / (1024**3)  # Convert to GB\n",
    "\n",
    "    return {\"cpu_usage\": cpu_usage, \"total_memory\": total_memory}\n",
    "\n",
    "# Get CPU and memory information\n",
    "info = get_cpu_and_memory_info()\n",
    "\n",
    "print(f\"CPU Usage: {info['cpu_usage']}%\")\n",
    "print(f\"Total Memory: {info['total_memory']:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd264cc1-8e29-4fc1-8dc0-06846aaf58dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 4\n",
      "GPU Name: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import psutil\n",
    "def get_gpu_info():\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        return gpu_count, gpu_name\n",
    "    else:\n",
    "        return 0, \"No GPU available\"\n",
    "# Get GPU information\n",
    "gpu_count, gpu_name = get_gpu_info()\n",
    "print(f\"Number of GPUs: {gpu_count}\")\n",
    "print(f\"GPU Name: {gpu_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e0b48-12b9-4ca1-8eda-617fe3f21be2",
   "metadata": {},
   "source": [
    "## Step 1 - Identification of Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c419fa98-f56f-42ea-8cdc-a88c9632b20c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are not on Google Colab.\n",
      "You are on SageMaker notebook instance.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  from IPython.core.display import get_ipython\n",
    "  is_colab =  get_ipython() is not None and get_ipython().get_fullname() == '__main__'\n",
    "except:\n",
    "  is_colab = False\n",
    "if is_colab:\n",
    "    print(\"You are on Google Colab!\")\n",
    "else:\n",
    "    print(\"You are not on Google Colab.\")\n",
    "    try:\n",
    "        import boto3\n",
    "        # Assuming you have IAM permissions to list SageMaker notebook instances\n",
    "        sagemaker_client = boto3.client('sagemaker')\n",
    "        response = sagemaker_client.list_notebook_instances()\n",
    "        # Check if any notebook instances are listed\n",
    "        if len(response['NotebookInstances']) > 0:\n",
    "            print(\"You are on SageMaker notebook instance.\")\n",
    "            is_sagemaker=True\n",
    "        else:\n",
    "            print(\"SageMaker API check inconclusive.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while checking with SageMaker API: {e}\")\n",
    "        print(\"Result inconclusive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16083b87-d5a4-452d-baa0-e0622ce87074",
   "metadata": {},
   "source": [
    "## Step 2 - Environment Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c1514b-e634-4b18-84ba-e77721b7c9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment name: pytorch_p310\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if is_colab:\n",
    "    #@markdown # Connect Google Drive\n",
    "    from google.colab import drive\n",
    "    from IPython.display import clear_output\n",
    "    import ipywidgets as widgets\n",
    "    import os\n",
    "    def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
    "    Shared_Drive = \"\" #@param {type:\"string\"}\n",
    "    #@markdown - Leave empty if you're not using a shared drive\n",
    "    print(\"[0;33mConnecting...\")\n",
    "    drive.mount('/content/gdrive')\n",
    "    if Shared_Drive!=\"\" and os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
    "      mainpth=\"Shareddrives/\"+Shared_Drive\n",
    "    else:\n",
    "      mainpth=\"MyDrive\"\n",
    "    clear_output()\n",
    "    inf('\\u2714 Done','success', '50px')\n",
    "    #@markdown ---\n",
    "else:\n",
    "    env_name = os.environ.get(\"CONDA_DEFAULT_ENV\", \"\")\n",
    "    if env_name == \"conda_pytorch_p310\":\n",
    "        print(\"Not detected Default Pytorch Environment\")\n",
    "        print(\"Installing missing packages\")\n",
    "        !pip3 install -qU torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "    else:\n",
    "        print(\"Environment name:\", env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e936faa-d31c-41e0-a4eb-15f94e7970f5",
   "metadata": {},
   "source": [
    "## Step 3 - Package Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7331fcd-837e-4150-8ee0-6dfa03e6e16a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if is_colab:\n",
    "    #@markdown # Install/Update ruslanmv repo\n",
    "    from IPython.utils import capture\n",
    "    from IPython.display import clear_output\n",
    "    from subprocess import getoutput\n",
    "    import ipywidgets as widgets\n",
    "    import sys\n",
    "    import fileinput\n",
    "    import os\n",
    "    import time\n",
    "    import base64\n",
    "    import requests\n",
    "    from urllib.request import urlopen, Request\n",
    "    from urllib.parse import urlparse, parse_qs, unquote\n",
    "    from tqdm import tqdm\n",
    "    import six\n",
    "    blsaphemy = base64.b64decode(\"ZWJ1aQ==\").decode('ascii')\n",
    "    if not os.path.exists(\"/content/gdrive\"):\n",
    "        print('\\033[1;31mGdrive not connected, using temporary colab storage ...')\n",
    "        time.sleep(4)\n",
    "        mainpth = \"MyDrive\"\n",
    "        !mkdir -p /content/gdrive/$mainpth\n",
    "        Shared_Drive = \"\"\n",
    "\n",
    "    if Shared_Drive != \"\" and not os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
    "        print('\\033[1;31mShared drive not detected, using default MyDrive')\n",
    "        mainpth = \"MyDrive\"\n",
    "\n",
    "    with capture.capture_output() as cap:\n",
    "        def inf(msg, style, wdth):\n",
    "            inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth))\n",
    "            display(inf)\n",
    "        fgitclone = \"git clone --depth 1\"\n",
    "        !mkdir -p /content/gdrive/$mainpth/llm\n",
    "        # Define the path\n",
    "        main_path =f\"/content/gdrive/{mainpth}/\"\n",
    "        !git clone -q --branch master https://github.com/ruslanmv/Automatic-Fine-Tunning /content/gdrive/$mainpth/llm/Automatic-Fine-Tunning\n",
    "        os.environ['TRANSFORMERS_CACHE'] = f\"/content/gdrive/{mainpth}/llm/Automatic-Fine-Tunning/{blsaphemy}/cache\"\n",
    "        os.environ['TORCH_HOME'] = f\"/content/gdrive/{mainpth}/llm/Automatic-Fine-Tunning/{blsaphemy}/cache\"\n",
    "        cache_dir = os.environ['TRANSFORMERS_CACHE']\n",
    "        !mkdir -p /content/gdrive/{mainpth}/llm/Automatic-Fine-Tunning/{blsaphemy}/repositories\n",
    "        !git clone https://github.com/ruslanmv/Automatic-Fine-Tunning /content/gdrive/{mainpth}/llm/Automatic-Fine-Tunning/{blsaphemy}/repositories/Automatic-Fine-Tunningebui-assets\n",
    "\n",
    "    with capture.capture_output() as cap:\n",
    "        %cd /content/gdrive/{mainpth}/llm/Automatic-Fine-Tunning/{blsaphemy}/repositories/Automatic-Fine-Tunningebui-assets\n",
    "\n",
    "        !git reset --hard\n",
    "        !git checkout master\n",
    "        time.sleep(1)\n",
    "        !git pull\n",
    "    clear_output()\n",
    "    inf('\\u2714 Done', 'success', '50px')\n",
    "    #@markdown ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f82eb4-08a4-4442-995a-effd278ebfd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\n",
      "pathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "def reload_environment():\n",
    "    # Kernel restart logic (may not work consistently within Jupyter Notebook)\n",
    "    try:\n",
    "      from IPython import get_ipython\n",
    "      get_ipython().kernel.do_shutdown(restart=True)\n",
    "      print(\"Kernel restarted. Packages should be reloaded.\")\n",
    "    except Exception as e:\n",
    "      print(f\"Kernel restart failed: {e}\")\n",
    "      print(\"Consider manually restarting the kernel or your Jupyter Notebook server.\")\n",
    "if is_colab:\n",
    "    #@markdown # Requirements\n",
    "    print('[1;32mInstalling requirements...')\n",
    "    with capture.capture_output() as cap:\n",
    "      %cd /content/\n",
    "      !wget -q -i https://github.com/ruslanmv/Automatic-Fine-Tunning/raw/master/Dependencies/requirements.txt\n",
    "      !pip install -r requirements.txt\n",
    "    clear_output()\n",
    "    inf('\\u2714 Done','success', '50px')\n",
    "    #@markdown ---\n",
    "if is_sagemaker:\n",
    "    #!pip install -qU transformers==4.36.2 accelerate==0.25.0 duckduckgo_search==4.1.0  python-dotenv\n",
    "    #!pip install -qU  bitsandbytes transformers==4.36.2 peft accelerate trl datasets==2.16.0 sentencepiece protobuf\n",
    "    !wget -q https://github.com/ruslanmv/Automatic-Fine-Tunning/raw/master/Dependencies/requirements.txt -O requirements.txt\n",
    "    !pip install -qU -r requirements.txt \n",
    "    #reload_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29228279-6247-43dc-9c69-030192a28322",
   "metadata": {},
   "source": [
    "##  Step 4  - Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f5174a2-6cd3-4f18-a9b8-701da2137ded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "import os,torch\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b881bfa-121a-43a3-abd6-d44cd47b131c",
   "metadata": {},
   "source": [
    "## Step 5 - Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db910d7-5b33-42fd-a104-2f968c0cb53d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base model from huggingFace or path to model\n",
    "base_model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "#base_model = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "# New model name\n",
    "\n",
    "#new_model = \"Medical-Mixtral-7B-v250k\"\n",
    "#num=256500\n",
    "\n",
    "new_model = \"Medical-Mixtral-7B-v2k\"\n",
    "num=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41088a83-f6a9-4820-8241-0400a05113d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HF Token\n"
     ]
    }
   ],
   "source": [
    "##  Loading Data\n",
    "# Access the environment variable\n",
    "if is_colab:\n",
    "    from google.colab import userdata\n",
    "    from google.colab import userdata\n",
    "    secret_hf = userdata.get('HF_TOKEN')\n",
    "else:\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    # Check if .env file exists\n",
    "    if not os.path.exists('.env'):\n",
    "        # Print the URL for Hugging Face token\n",
    "        print(\"Please go to the following URL and obtain your Hugging Face token:\")\n",
    "        print(\"https://huggingface.co/settings/tokens\")\n",
    "        print()\n",
    "        # Prompt user to enter HF_TOKEN manually\n",
    "        hf_token = input(\"Please enter your Hugging Face token: \")\n",
    "\n",
    "        # Create or append to .env file\n",
    "        with open('.env', 'a') as f:\n",
    "            f.write(f\"HF_TOKEN={hf_token}\\n\")\n",
    "\n",
    "    # Load the .env file\n",
    "    load_dotenv()\n",
    "    # Retrieve the value of HF_TOKEN from the environment variables\n",
    "    secret_hf = os.environ.get('HF_TOKEN')\n",
    "    # Clear output to hide the token\n",
    "    from IPython.display import clear_output\n",
    "    clear_output()\n",
    "    # Print the value of HF_TOKEN\n",
    "    print(\"Loaded HF Token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5257211-b39d-4843-ac33-c7a990fde80c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/ec2-user/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Then you can use the token in your command\n",
    "!huggingface-cli login --token $secret_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3619f3a5-0b94-4b0b-930a-2aa3447e7d7a",
   "metadata": {},
   "source": [
    "## Step 6 -  Datataset to Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a93e69ee-b9d1-4431-84bb-6b682cebb212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcb118b36344bca99fb853d5301f936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/863 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9c9a95d0b44e048b88991405bf3bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/142M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddf8c1aa28a4d6984d6c2e5c52c6dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/256916 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_ = load_dataset(\"ruslanmv/ai-medical-chatbot\")\n",
    "train_data = dataset_[\"train\"]\n",
    "df = pd.DataFrame(train_data[::])\n",
    "df = df[[\"Description\", \"Doctor\"]].rename(columns={\"Description\": \"question\", \"Doctor\": \"answer\"})\n",
    "# Clean the question and answer columns\n",
    "df['question'] = df['question'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
    "df['answer'] = df['answer'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
    "# Assuming your DataFrame is named 'df' and the column is named 'df' and the column is named 'question'\n",
    "df['question'] = df['question'].str.lstrip('Q. ')\n",
    "df['answer'] = df['answer'].str.replace('-->', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5210724-2cd6-4955-8754-11a51b322457",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What does abutment of the nerve root mean?</td>\n",
       "      <td>Hi. I have gone through your query with dilige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What should I do to reduce my weight gained du...</td>\n",
       "      <td>Hi. You have really done well with the hypothy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have started to get lots of acne on my face,...</td>\n",
       "      <td>Hi there Acne has multifactorial etiology. Onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why do I have uncomfortable feeling between th...</td>\n",
       "      <td>Hello. The popping and discomfort what you fel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My symptoms after intercourse threatns me even...</td>\n",
       "      <td>Hello. The HIV test uses a finger prick blood ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0         What does abutment of the nerve root mean?   \n",
       "1  What should I do to reduce my weight gained du...   \n",
       "2  I have started to get lots of acne on my face,...   \n",
       "3  Why do I have uncomfortable feeling between th...   \n",
       "4  My symptoms after intercourse threatns me even...   \n",
       "\n",
       "                                              answer  \n",
       "0  Hi. I have gone through your query with dilige...  \n",
       "1  Hi. You have really done well with the hypothy...  \n",
       "2  Hi there Acne has multifactorial etiology. Onl...  \n",
       "3  Hello. The popping and discomfort what you fel...  \n",
       "4  Hello. The HIV test uses a finger prick blood ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab1ac366-a6f9-4ad2-8f5e-44f328d66d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df.iloc[:num, :]\n",
    "df_test = df.iloc[num:num+100, :]\n",
    "# Save the train dataframe to a CSV file\n",
    "df_train.to_csv('train.csv', index=False)\n",
    "# Save the test dataframe to a CSV file\n",
    "df_test.to_csv('test.csv', index=False)\n",
    "df=df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3405fc-59a1-4c6f-bf08-018f52be3a40",
   "metadata": {},
   "source": [
    "## Step 7 - Formatting Your Fine-tuning Data\n",
    "There are various ways to format your data for fine-tuning\n",
    "\n",
    "Prompts provide context and guide the LLM towards the desired task. The code showcases creating prompts for question-answering tasks with placeholders for questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d12f6a-a784-4cee-a260-37014d689c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build training dataset with the right format\n",
    "df['text'] = '[INST]@Enlighten. ' + df['question'] +'[/INST]'+ df['answer'] + ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21649658-4ea1-488e-9911-928bd159ba95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove columns\n",
    "df=df.drop(['question','answer'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7382ad6-5515-4c7f-a725-58b5c07d43f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[INST]@Enlighten. What does abutment of the ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST]@Enlighten. What should I do to reduce m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[INST]@Enlighten. I have started to get lots o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[INST]@Enlighten. Why do I have uncomfortable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[INST]@Enlighten. My symptoms after intercours...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [INST]@Enlighten. What does abutment of the ne...\n",
       "1  [INST]@Enlighten. What should I do to reduce m...\n",
       "2  [INST]@Enlighten. I have started to get lots o...\n",
       "3  [INST]@Enlighten. Why do I have uncomfortable ...\n",
       "4  [INST]@Enlighten. My symptoms after intercours..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "995f72c6-1ec7-4de2-82d1-941ec3f824db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ba91adc-a68a-476b-a17a-ddfdb67c56bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to dataset object\n",
    "dataset = ds.dataset(pa.Table.from_pandas(df).to_batches())\n",
    "dataset = Dataset(pa.Table.from_pandas(df))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91e4da5b-43ad-4c62-b25a-4aaf703aeff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38fbcbf1-997c-479b-9936-10dfb3ef1c05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 3368\n",
      "Min length: 106\n",
      "Mean length: 646.119\n",
      "Median length: 606\n"
     ]
    }
   ],
   "source": [
    "statistics=True\n",
    "#dataset_sample = dataset.select(range(500)) # Take only the first 500 records from the dataset\n",
    "if statistics: \n",
    "    sequence_lengths = [len(example['text']) for example in dataset]\n",
    "    # Calculate statistics\n",
    "    max_length = max(sequence_lengths)\n",
    "    min_length = min(sequence_lengths)\n",
    "    mean_length = sum(sequence_lengths) / len(sequence_lengths)\n",
    "    median_length = sorted(sequence_lengths)[len(sequence_lengths) // 2]\n",
    "    print(\"Max length:\", max_length)\n",
    "    print(\"Min length:\", min_length)\n",
    "    print(\"Mean length:\", mean_length)\n",
    "    print(\"Median length:\", median_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef947cf3-5c34-4b8a-8bea-82f364c98b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_sagemaker:\n",
    "    # Get the current directory and join with the models folder\n",
    "    current_directory = os.getcwd()\n",
    "    cache_dir = os.path.join(current_directory, \"models\")\n",
    "    main_path=current_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa098e-4f75-47f6-ac0e-7d03323148f1",
   "metadata": {},
   "source": [
    "## Step 8 -  Downloading and Initializing Mixtral 8x7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fbae860-d582-474a-b348-babfba9abce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effc888f9220404f925f83a3fe321a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2682154fadc49a8b0744eeddd910a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd099b2a334942a5b36b17d15d27f538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88eb00ddb62d49a9aece98ddf4f1a1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea98e8f24e046c9867576336110ad6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd06572bfb6a4dafb9e371335e6d4341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load base model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit= True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant= False,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        load_in_4bit=True,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        cache_dir=cache_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9119bed9-3bf8-4ab5-9295-c3a9d9571fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.config.use_cache = False # silence the warnings. Please re-enable for inference!\n",
    "model.config.pretraining_tp = 1\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c022551-c1f7-4f61-916e-d4efdfad9434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee17cb8037414b0494c496578326076c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1690894ad0214aac9666807c92437a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1724ec7d4da4cc3b8c0df32c0612127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a07c95d77f48a7aee07ca93f9069a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('<s>', '</s>')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True, cache_dir=cache_dir)\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.bos_token, tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3735c09-7e48-46a0-a46f-9cda5d3219ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.model_max_length = 1024  # Adjust this value based on your dataset and GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61dfe4a6-92cd-450d-87f2-06bea8deb3de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_training=False\n",
    "if count_training:\n",
    "    # count trainging tokens\n",
    "    from transformers import LlamaTokenizer\n",
    "    tokenizer_ = LlamaTokenizer.from_pretrained(\"cognitivecomputations/dolphin-llama2-7b\",\n",
    "                                                cache_dir=cache_dir)\n",
    "    tokens = tokenizer_.tokenize(dataset.to_pandas().to_string())\n",
    "    len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70c3f55-4c99-4234-b9ac-e90c3d76d049",
   "metadata": {},
   "source": [
    "## Step 9 - Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e8ce2be-67aa-4de2-8391-7dab57836edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Adding the adapters in the layers\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e9c7e38-6127-4b89-9c14-635fc3875de1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Hyperparamter\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=50,\n",
    "    logging_steps=1,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c5b64b8-ec90-4689-9f7c-2a4a07940a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17f4b7fff9941e1832f6d9b67b9007f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting sft parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    #max_seq_length= None,\n",
    "    max_seq_length=1024,  # Adjust based on your dataset and GPU memory\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a11232b1-4778-4fa3-9050-d23d9db0a41e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13cf914-bf95-47ea-acbe-f4d7a400e374",
   "metadata": {},
   "source": [
    "## Step 10 - Save and push the adapter to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f0bdfda-3e16-4995-9b56-18e049e18e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "save_path = os.path.join(main_path, \"llm\", \"Automatic-Fine-Tuning\", \"models\", new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16cdff78-83c8-4be9-ade3-098b26379c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/container/llm/Automatic-Fine-Tuning/models/Medical-Mixtral-7B-v2k'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcf6257a-2820-4b45-bb3e-9c3641dd2d47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7147b8bf-4bb3-44e2-b075-ff35e4f42ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model configuration\n",
    "model.config.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c89193ee-80e3-45fd-a456-b04e5ee4154a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Saving\n",
    "trainer.model.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbd61548-b61a-4ac7-9f61-1f7ec83fb3b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/ec2-user/SageMaker/container/llm/Automatic-Fine-Tuning/models/Medical-Mixtral-7B-v2k/tokenizer_config.json',\n",
       " '/home/ec2-user/SageMaker/container/llm/Automatic-Fine-Tuning/models/Medical-Mixtral-7B-v2k/special_tokens_map.json',\n",
       " '/home/ec2-user/SageMaker/container/llm/Automatic-Fine-Tuning/models/Medical-Mixtral-7B-v2k/tokenizer.model',\n",
       " '/home/ec2-user/SageMaker/container/llm/Automatic-Fine-Tuning/models/Medical-Mixtral-7B-v2k/added_tokens.json',\n",
       " '/home/ec2-user/SageMaker/container/llm/Automatic-Fine-Tuning/models/Medical-Mixtral-7B-v2k/tokenizer.json')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f6932c2-a1ea-40b5-80ca-12a7ad2fffcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c22de-7eb0-4143-8560-96c39bdaf474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf20600-e902-4b67-ab7f-d36396e49ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6521eae-83f9-4612-856d-287b9b32321a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creation of te README.md\n",
    "# Example of use\n",
    "example = f'''\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer ,pipeline, logging, BitsAndBytesConfig\n",
    "import os,torch\n",
    "# Define the name of your fine-tuned model\n",
    "finetuned_model = 'ruslanmv/{new_model}'\n",
    "\n",
    "# Load fine-tuned model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit= True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant= False,\n",
    ")\n",
    "model_pretrained = AutoModelForCausalLM.from_pretrained(\n",
    "        finetuned_model,\n",
    "        load_in_4bit=True,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    ")\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(finetuned_model,\n",
    "                                          trust_remote_code=True)\n",
    "\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\",\n",
    "                model=model_pretrained, \n",
    "                tokenizer=tokenizer, max_length=500)\n",
    "def build_prompt(question):\n",
    "  prompt=f\"[INST]@Enlighten. [/INST] {question}\"\n",
    "  return prompt\n",
    "\n",
    "question = \"Are my symptoms due to HIV infection? I had a high-risk exposure 15 months ago\"\n",
    "prompt = build_prompt(question)\n",
    "result = pipe(prompt)\n",
    "print(result[0]['generated_text'])\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "# Create a Model Card\n",
    "model_card = {\n",
    "    \"Model Name\": \"{}\".format(new_model),\n",
    "    \"Description\": \"Fine-tuned Mixtral model for answering medical assistance questions. This model is a novel version of mistralai/Mixtral-8x7B-Instruct-v0.1, adapted to a subset of {}k records from the AI Medical Chatbot dataset, which contains 250k records (https://huggingface.co/datasets/ruslanmv/ai-medical-chatbot). The purpose of this model is to provide a ready chatbot to answer questions related to medical assistance.\".format(num/1000),\n",
    "    \"Intended Use\": \"This model is intended for providing assistance and answering questions related to medical inquiries. It is suitable for use in chatbot applications where users seek medical advice, information, or assistance.\",\n",
    "    \"Example Usage 1\": example,\n",
    "    \"Training Data\": {\n",
    "        \"Dataset Name\": \"AI Medical Chatbot\",\n",
    "        \"Dataset URL\": \"https://huggingface.co/datasets/ruslanmv/ai-medical-chatbot\",\n",
    "        \"Dataset Size\": \"250k records\",\n",
    "        \"Subset Used\": \"{}k records\".format(num/1000)\n",
    "    },\n",
    "    \"Limitations\": [\n",
    "        \"The model's performance may vary depending on the complexity and specificity of the medical questions.\",\n",
    "        \"The model may not provide accurate answers for every medical query, and users should consult medical professionals for critical healthcare concerns.\"\n",
    "    ],\n",
    "    \"Ethical Considerations\": [\n",
    "        \"Users should be informed that the model's responses are generated based on patterns in the training data and may not always be accurate or suitable for medical decision-making.\",\n",
    "        \"The model should not be used as a replacement for professional medical advice or diagnosis.\",\n",
    "        \"Sensitive patient data should not be shared with the model, and user privacy should be protected.\"\n",
    "    ]\n",
    "}\n",
    "# Additional information\n",
    "library_name = \"peft\"\n",
    "repository_name = f\"ruslanmv/{new_model}\"  # Specify the repository name here\n",
    "# Generate README content\n",
    "readme_content = f\"\"\"---\n",
    "library_name: {library_name}\n",
    "base_model: {base_model}\n",
    "---\n",
    "\n",
    "# {model_card['Model Name']}\n",
    "\n",
    "## Description\n",
    "{model_card['Description']}\n",
    "\n",
    "## Intended Use\n",
    "{model_card['Intended Use']}\n",
    "\n",
    "## Installation \n",
    "\n",
    "pip install -qU  transformers==4.36.2  datasets python-dotenv peft bitsandbytes accelerate\n",
    "\n",
    "## Example Usage\n",
    "```python\n",
    "{model_card['Example Usage 1']}\n",
    "```\n",
    "\n",
    "For Gpus\n",
    "```python\n",
    "{model_card['Example Usage 2']}\n",
    "```\n",
    "\n",
    "## Training Data\n",
    "- **Dataset Name:** {model_card['Training Data']['Dataset Name']}\n",
    "- **Dataset URL:** {model_card['Training Data']['Dataset URL']}\n",
    "- **Dataset Size:** {model_card['Training Data']['Dataset Size']}\n",
    "- **Subset Used:** {model_card['Training Data']['Subset Used']}\n",
    "\n",
    "## Limitations\n",
    "{model_card['Limitations'][0]}\n",
    "{model_card['Limitations'][1]}\n",
    "\n",
    "## Ethical Considerations\n",
    "{model_card['Ethical Considerations'][0]}\n",
    "{model_card['Ethical Considerations'][1]}\n",
    "{model_card['Ethical Considerations'][2]}\n",
    "\"\"\"\n",
    "# Write README content to a file\n",
    "with open(\"README.md\", \"w\") as readme_file:\n",
    "    readme_file.write(readme_content)\n",
    "    \n",
    "import json\n",
    "# Save the Model Card\n",
    "model_card_path = os.path.join(save_path, \"model_card.json\")\n",
    "with open(model_card_path, \"w\") as f:\n",
    "    json.dump(model_card, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd676db2-a643-4a68-bd65-bbcdca04fbfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "718cb687-bf1e-42c8-ba00-e19a8895c955",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ruslanmv/Medical-Mixtral-7B-v2k/commit/199267885dfa064f2ce40581a2fef3fddad3e963', commit_message='Upload tokenizer', commit_description='', oid='199267885dfa064f2ce40581a2fef3fddad3e963', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push the model to the Hub, specifying the repository ID and any other optional parameters\n",
    "model.push_to_hub(\n",
    "    repo_id=new_model,  # Replace with your model\n",
    "    use_temp_dir=True,  # Optional, whether to use a temporary directory\n",
    "    commit_message=\"Upload \" + new_model,  # Commit message with new_model name\n",
    "    private=False,  # Optional, whether the repository should be private\n",
    "    token=True,  # Optional, specify token or use default\n",
    "    max_shard_size=\"5GB\",  # Optional, maximum size for a checkpoint before being sharded\n",
    "    create_pr=False,  # Optional, whether to create a PR\n",
    "    safe_serialization=True,  # Optional, convert model weights to safetensors format\n",
    "    revision=None,  # Optional, branch to push the uploaded files to\n",
    "    commit_description=None,  # Optional, description of the commit\n",
    "    model_card=model_card_path\n",
    ")\n",
    "#trainer.model.push_to_hub(new_model)\n",
    "tokenizer.push_to_hub(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d0813bb-3e2e-4a6b-813e-b7f095a9037e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ruslanmv/Medical-Mixtral-7B-v2k/commit/9d407ce7d17d62de058064ef21b5b6682f265295', commit_message='Upload tokenizer', commit_description='', oid='9d407ce7d17d62de058064ef21b5b6682f265295', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d97948-a8de-45ce-9eb7-15b01b594b95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#help(model.push_to_hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89aa646c-3fe1-4f15-9744-350e415a10df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save config.json\n",
    "config_path_json = os.path.join(save_path, \"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db803a5e-2a69-47b4-8e43-f3d0bfa89e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "# Authenticate with Hugging Face \n",
    "api = HfApi()  # Replace with your authentication method\n",
    "# Path to your README.md file\n",
    "\n",
    "def upload_file(path, repository_name, path_in_repo):\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=path,\n",
    "        repo_id=repository_name,\n",
    "        path_in_repo=path_in_repo  # Add this argument\n",
    "    )\n",
    "    print(f\"{path_in_repo} uploaded to {repository_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f9212b2-bef6-4722-8984-1ff3c625ed72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md uploaded to ruslanmv/Medical-Mixtral-7B-v2k\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "# Combine the current directory with the README.md filename\n",
    "readme_path = os.path.join(current_directory, \"README.md\")\n",
    "# Upload the file to the root of the repository (\"\")\n",
    "path_in_repo=\"README.md\"\n",
    "upload_file(readme_path, repository_name, path_in_repo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "015e7ccd-6058-4a6a-a762-65e8702abbaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json uploaded to ruslanmv/Medical-Mixtral-7B-v2k\n"
     ]
    }
   ],
   "source": [
    "config_path = os.path.join(save_path, \"config.json\")\n",
    "# Upload the file to the root of the repository (\"\")\n",
    "path_in_repo=\"config.json\"\n",
    "upload_file(config_path, repository_name, path_in_repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6908ef00-22ad-4d9e-9df7-4da73be4262e",
   "metadata": {},
   "source": [
    "## Step 11 - Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2996e30e-cdbf-47a1-b929-51bfb004be02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c25c7cf7-277d-4044-b473-06cc96209026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(question):\n",
    "  prompt=f\"[INST]@Enlighten. {question} [/INST]\"\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76feda9e-0264-4c0d-9914-ee4baff102d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"What does abutment of the nerve root mean?\"\n",
    "prompt = build_prompt(question)\n",
    "result = pipe(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "accb7a62-0636-4d6d-a51a-29b4ccb16a92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]@Enlighten. What does abutment of the nerve root mean? [/INST]Hi. I have gone through your query with diligence and would like you to know that I am here to help you. For further information consult a neurologist online ― ₹200. All the best. For more information consult a neurologist online ― ₹200. All the best. For more information consult a neurologist online ― ₹200. All the best. For more information consult a neurologist online ― ₹200. All the best. For more information consult a neurologist online ― ₹200. All the best. For more information consult a neurologist online ― ₹200. All the best. For more information consult a neurologist online ― ₹200. All the best. For more information consult\n"
     ]
    }
   ],
   "source": [
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89eed049-0ef5-465b-8665-5aa3a725de0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_path=\"test.csv\"\n",
    "test_path=\"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "234bddf8-f0b4-438c-a702-a7131ec14456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_test=pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "12660cdc-a758-4d79-a0dc-721f16d3d243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>Can Yasmin birth control pill be used as an em...</td>\n",
       "      <td>Hi. How are you doing? Yes, as you have heard,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Please explain the poisonous effect of phenol ...</td>\n",
       "      <td>Hi. I want to assure you not to worry as every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>For how long should I take Kalachikai powder t...</td>\n",
       "      <td>Hello. For PCOD (polycystic ovarian disease), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>Why do periods get delayed after first time sex?</td>\n",
       "      <td>Hello. As the serum beta hCG levels are less t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>How to resolve peripheral vision problem?</td>\n",
       "      <td>Hi. Revert back with the report and answers to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "2000  Can Yasmin birth control pill be used as an em...   \n",
       "2001  Please explain the poisonous effect of phenol ...   \n",
       "2002  For how long should I take Kalachikai powder t...   \n",
       "2003   Why do periods get delayed after first time sex?   \n",
       "2004          How to resolve peripheral vision problem?   \n",
       "\n",
       "                                                 answer  \n",
       "2000  Hi. How are you doing? Yes, as you have heard,...  \n",
       "2001  Hi. I want to assure you not to worry as every...  \n",
       "2002  Hello. For PCOD (polycystic ovarian disease), ...  \n",
       "2003  Hello. As the serum beta hCG levels are less t...  \n",
       "2004  Hi. Revert back with the report and answers to...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d65073c7-14a8-4772-94f5-c8d36e97083b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We test only 10 entries\n",
    "df_test=df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c59dc51e-9ca7-4018-9a93-82bd560336d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>Can Yasmin birth control pill be used as an em...</td>\n",
       "      <td>Hi. How are you doing? Yes, as you have heard,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Please explain the poisonous effect of phenol ...</td>\n",
       "      <td>Hi. I want to assure you not to worry as every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>For how long should I take Kalachikai powder t...</td>\n",
       "      <td>Hello. For PCOD (polycystic ovarian disease), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>Why do periods get delayed after first time sex?</td>\n",
       "      <td>Hello. As the serum beta hCG levels are less t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>How to resolve peripheral vision problem?</td>\n",
       "      <td>Hi. Revert back with the report and answers to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>Is there any way to treat pinworm infestation ...</td>\n",
       "      <td>Hi. Best is Ivermectin. If resistant, use 5 % ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>What are the ways to get pregnant without pene...</td>\n",
       "      <td>Hi, WeIcome to icliniq.com. I can understand y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>Can I take PPI to treat gurgling caused due to...</td>\n",
       "      <td>Hi. PPI alone will not work. Need to add some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>What should I do to be happy all over the day ...</td>\n",
       "      <td>Hello. First of all, you should stop hating yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>Kindly explain well defined altered cystic sig...</td>\n",
       "      <td>Hello. Regarding your question, I would explai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "2000  Can Yasmin birth control pill be used as an em...   \n",
       "2001  Please explain the poisonous effect of phenol ...   \n",
       "2002  For how long should I take Kalachikai powder t...   \n",
       "2003   Why do periods get delayed after first time sex?   \n",
       "2004          How to resolve peripheral vision problem?   \n",
       "2005  Is there any way to treat pinworm infestation ...   \n",
       "2006  What are the ways to get pregnant without pene...   \n",
       "2007  Can I take PPI to treat gurgling caused due to...   \n",
       "2008  What should I do to be happy all over the day ...   \n",
       "2009  Kindly explain well defined altered cystic sig...   \n",
       "\n",
       "                                                 answer  \n",
       "2000  Hi. How are you doing? Yes, as you have heard,...  \n",
       "2001  Hi. I want to assure you not to worry as every...  \n",
       "2002  Hello. For PCOD (polycystic ovarian disease), ...  \n",
       "2003  Hello. As the serum beta hCG levels are less t...  \n",
       "2004  Hi. Revert back with the report and answers to...  \n",
       "2005  Hi. Best is Ivermectin. If resistant, use 5 % ...  \n",
       "2006  Hi, WeIcome to icliniq.com. I can understand y...  \n",
       "2007  Hi. PPI alone will not work. Need to add some ...  \n",
       "2008  Hello. First of all, you should stop hating yo...  \n",
       "2009  Hello. Regarding your question, I would explai...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3fe3d197-4ce1-4f4b-a729-5d9f122bcf87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################\n",
      "Answer the following question, at the end of your response say thank you for your query.\n",
      "Can Yasmin birth control pill be used as an emergency contraceptive pill?\n",
      "\n",
      "LLM Answer:\n",
      "Hi. How are you doing? Yes, as you have heard, Yasmin can be used as an emergency pill. Even if you have not ejaculated into her, she stands a chance of pregnancy if the pre-seminal fluid, the clear fluid that comes out before semen, which is rich in young healthy sperms, comes in contact with her genitals. As soon as possible, earlier than 72 hours, I suggest taking four tablets of Yasmin (combination of Ethinyl Estradiol and Drospirenone) at the time, repeat four more tablets after 12 hours. This being a high dose of hormones, it will suddenly increase the inner l\n",
      "correct\n",
      "Progress: 0.1\n",
      "Accuracy: 1.0\n",
      "#############################\n",
      "Answer the following question, at the end of your response say thank you for your query.\n",
      "Please explain the poisonous effect of phenol ingestion.\n",
      "\n",
      "LLM Answer:\n",
      "Hi. I want to assure you not to worry as everything is going to be fine if proper care and treatment is opted in for. I have thoroughly gone through your case and can well understand your genuine health concerns. 1. No, there is not much problem right now as he vomited and also had a lot of water. It is fine because it was only two drops. 2. We usually do not go for emesis (vomiting) for phenol poisoning cases. Because, it is a volatile compound and causes vapors entering the lungs through the airways. 1. He should avoid re-exposure. 2. For further follow up consult a general practitioner online.- Thanks. For more information consult a general\n",
      "correct\n",
      "Progress: 0.2\n",
      "Accuracy: 1.0\n",
      "#############################\n",
      "Answer the following question, at the end of your response say thank you for your query.\n",
      "For how long should I take Kalachikai powder to overcome PCOD problem?\n",
      "\n",
      "LLM Answer:\n",
      "Hello. For PCOD (polycystic ovarian disease), powder Kalachikai has a good effect, but the duration of treatment is long (more than three months). For proper evaluation of disease, please go for USG whole abdomen and other investigations. If the size and number of cysts are more, then I suggest consulting a gynecologist for physical evaluation and possible surgical intervention. If the number and size of cysts are less, you may continue treatment along with syrup Evecare 10 ml BD and Kanchnar Guggulu two BD. For more information consult an ayurveda specialist online √ Thank you for your query. For more\n",
      "correct\n",
      "Progress: 0.3\n",
      "Accuracy: 1.0\n",
      "#############################\n",
      "Answer the following question, at the end of your response say thank you for your query.\n",
      "Why do periods get delayed after first time sex?\n",
      "\n",
      "LLM Answer:\n",
      "Hello. As the serum beta hCG levels are less than 3 mIU/mL, the pregnancy is definitely ruled out. The delay in the menses is mostly due to sex induced stress after the first time when reproductive hormones readjust themselves. The menses can get delayed even up to two weeks, so just wait for another week and they should arrive. If not, then you can safely opt for a progesterone withdrawal to resume menses. For further information consult an obstetrician and gynaecologist online ▶️. All the best. For more information consult an obstetrician and gynaecologist online ▶️. Thank you for your query. All the best. For more information consult an obstetrician and\n",
      "correct\n",
      "Progress: 0.4\n",
      "Accuracy: 1.0\n",
      "#############################\n",
      "Answer the following question, at the end of your response say thank you for your query.\n",
      "How to resolve peripheral vision problem?\n",
      "\n",
      "LLM Answer:\n",
      "Hello. I understand your concern. I have gone through your query and understand that you are suffering from a condition called as peripheral neuropathy. This is a condition where the nerves in the periphery of the body are affected. The exact cause of this condition is not known. However, it is usually associated with diabetes, alcoholism, and certain medications. I would suggest you to get a detailed neurological examination done and get a nerve conduction study done. This will help you to know the exact cause of your condition. I hope this has helped you. If you require any further queries, please do not hesitate to contact me. Thank you for your query. For more information consult a neurologist online ▶️ ☎️ Follow up: Get a\n",
      "wrong\n",
      "Progress: 0.5\n",
      "Accuracy: 0.8\n",
      "#############################\n",
      "Answer the following question, at the end of your response say thank you for your query.\n",
      "Is there any way to treat pinworm infestation permanently?\n",
      "\n",
      "LLM Answer:\n",
      "Hello. I understand your concern. I have gone through your query and understand that you are suffering from pinworm infestation. I would like to assure you that you will be fine after taking the medicines. I would also like to inform you that pinworm infestation is a common problem and it is not a serious one. I would like to suggest you the following medicines: Consult your specialist doctor, discuss with him or her and start taking the medicines with their consent. I would also like to suggest you the following measures to prevent pinworm infestation: I hope I have clarified your query. Do write back if you have any more queries. All the best. Thank you for your query. For more information consult a\n",
      "correct\n",
      "Progress: 0.6\n",
      "Accuracy: 0.8333333333333334\n",
      "#############################\n",
      "Answer the following question, at the end of your response say thank you for your query.\n",
      "What are the ways to get pregnant without penetration?\n",
      "\n",
      "LLM Answer:\n",
      "Hello. I understand your concern. I would like to assure you that you are not alone in this. I would also like to assure you that you can get pregnant without penetration. You can get pregnant by oral sex, anal sex, and even by touching your genitals. I would also like to assure you that you can get pregnant even if you have not had sex. I would also like to assure you that you can get pregnant even if you have not had sex for a long time. I would also like to assure you that you can get pregnant even if you have not had sex for a long time. I would also like to assure you that you can get pregnant even if you have not had sex for a long time. I would also like to assure you that you\n",
      "correct\n",
      "Progress: 0.7\n",
      "Accuracy: 0.8571428571428571\n",
      "#############################\n",
      "Answer the following question, at the end of your response say thank you for your query.\n",
      "Can I take PPI to treat gurgling caused due to GERD?\n",
      "\n",
      "LLM Answer:\n",
      "Hello. I understand your concern. I have gone through your query and understand that you are suffering from GERD (gastroesophageal reflux disease). I would suggest you to take the following medications: 1. Tablet Omeprazole 20 mg once daily for 15 days. 2. Tablet Domperidone 10 mg twice daily for 15 days. 3. Tablet Pantoprazole 40 mg once daily for 15 days. 4. Tablet Rabeprazole 20 mg once daily for 15 days. 5. Tablet Esomeprazole 40 mg once daily for 15 days\n",
      "correct\n",
      "Progress: 0.8\n",
      "Accuracy: 0.875\n",
      "#############################\n",
      "Answer the following question, at the end of your response say thank you for your query.\n",
      "What should I do to be happy all over the day inspite of hurting myself?\n",
      "\n",
      "LLM Answer:\n",
      "Hello. I understand your concern. I would like to assure you that you are not alone in this. I would like to suggest you the following: Consult a psychiatrist online for follow up ☑️ For more information consult a psychiatrist online ☑️ 1. You can start with a mood stabilizer like Lamotrigine. 2. You can also start with a selective serotonin reuptake inhibitor (SSRI) like Fluoxetine. 3. You can also try psychotherapy. 4. You can also try meditation and yoga. 5. You can also try to do some physical activity. 6. You can also try to do some hobbies\n",
      "correct\n",
      "Progress: 0.9\n",
      "Accuracy: 0.8888888888888888\n",
      "#############################\n",
      "Answer the following question, at the end of your response say thank you for your query.\n",
      "Kindly explain well defined altered cystic signal intensity along nerves in MRI.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Answer:\n",
      "Hello. I have gone through your query and understand your concerns. For further information consult a neurologist online ☑️. For more information consult a neurologist online ☑️. For more information consult a neurologist online ☑️. For more information consult a neurologist online ☑️. For more information consult a neurologist online ☑️. For more information consult a neurologist online ☑️. For more information consult a neurologist online ☑️. For more information consult a neurologist online ☑️. For more information consult a neurologist online ☑️. For more information\n",
      "correct\n",
      "Progress: 1.0\n",
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "questionCounter = 0\n",
    "correct = 0\n",
    "promptEnding = \"[/INST]\"\n",
    "\n",
    "# Guide for answering questions\n",
    "testGuide = 'Answer the following question, at the end of your response say thank you for your query.\\n'\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in df_test.iterrows():\n",
    "    print(\"#############################\")\n",
    "    questionCounter += 1\n",
    "\n",
    "    # Build the question prompt\n",
    "    question = testGuide + row['question'] + \"\\n\"\n",
    "    print(question)\n",
    "\n",
    "    # Get the true answer\n",
    "    truth = row['answer']\n",
    "\n",
    "    # Build the prompt\n",
    "    prompt = build_prompt(question)\n",
    "\n",
    "    # Generate answer\n",
    "    result = pipe(prompt)\n",
    "    llmAnswer = result[0]['generated_text']\n",
    "\n",
    "    # Remove the prompt from the generated answer\n",
    "    index = llmAnswer.find(promptEnding)\n",
    "    llmAnswer = llmAnswer[len(promptEnding) + index:]\n",
    "\n",
    "    print(\"LLM Answer:\")\n",
    "    print(llmAnswer)\n",
    "\n",
    "    # Remove spaces from the generated answer\n",
    "    llmAnswer = llmAnswer.replace(' ', '')\n",
    "\n",
    "    # Find the option in response\n",
    "    index = llmAnswer.find('answer:')\n",
    "\n",
    "    # Find and match the option\n",
    "    next_char = llmAnswer[index + len('answer:'):][0]\n",
    "    if next_char in truth:\n",
    "        correct += 1\n",
    "        print('correct')\n",
    "    else:\n",
    "        print('wrong')\n",
    "\n",
    "    # Update accuracy\n",
    "    accuracy = correct / questionCounter\n",
    "    print(f\"Progress: {questionCounter / len(df_test)}\")\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32482f71-23e0-40cc-a1a9-bb1234b680f1",
   "metadata": {},
   "source": [
    "# Medical-Mixtral-7B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d7f098-6492-42c4-9fae-0584ed266976",
   "metadata": {},
   "source": [
    "### Testing model created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "720cb413-5871-4222-8bc4-29238a4b6a88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dca96ee2ab4b67a5af7b94b4107227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, logging, BitsAndBytesConfig\n",
    "import os, torch\n",
    "\n",
    "# Define the name of your fine-tuned model\n",
    "finetuned_model = 'ruslanmv/Medical-Mixtral-7B-v2k'\n",
    "\n",
    "# Load fine-tuned model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "model_pretrained = AutoModelForCausalLM.from_pretrained(\n",
    "    finetuned_model,\n",
    "    load_in_4bit=True,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(finetuned_model, trust_remote_code=True)\n",
    "\n",
    "# Set pad_token_id to eos_token_id\n",
    "model_pretrained.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model_pretrained, tokenizer=tokenizer, max_length=100)\n",
    "\n",
    "def build_prompt(question):\n",
    "  prompt=f\"[INST]@Enlighten. {question} [/INST]\"\n",
    "  return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd573d25-ab7b-46a0-9629-4cf19762c53f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. I understand your concerns. I would like to assure you that you are not at risk of HIV infection. I hope this has helped you. Do write back if you have any more queries. All the best. For more information consult an internal medicine physician online ➜ www.iclinic.com/hiv\n"
     ]
    }
   ],
   "source": [
    "question = \"Are my symptoms due to HIV infection? I had a high-risk exposure 15 months ago\"\n",
    "prompt = build_prompt(question)\n",
    "\n",
    "# Generate text based on the prompt\n",
    "result = pipe(prompt)[0]\n",
    "generated_text = result['generated_text']\n",
    "\n",
    "# Remove the prompt from the generated text\n",
    "generated_text = generated_text.replace(prompt, \"\", 1).strip()\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c532313-b277-4c39-89c2-86fa5c64e10f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask(question):\n",
    "  promptEnding = \"[/INST]\"\n",
    "  # Guide for answering questions\n",
    "  testGuide = 'Answer the following question, at the end of your response say thank you for your query.\\n'\n",
    "  # Build the question prompt\n",
    "  question = testGuide + question + \"\\n\"\n",
    "  print(question)\n",
    "  # Build the prompt\n",
    "  prompt = build_prompt(question)\n",
    "  # Generate answer\n",
    "  result = pipe(prompt)\n",
    "  llmAnswer = result[0]['generated_text']\n",
    "  # Remove the prompt from the generated answer\n",
    "  index = llmAnswer.find(promptEnding)\n",
    "  llmAnswer = llmAnswer[len(promptEnding) + index:]\n",
    "  print(\"LLM Answer:\")\n",
    "  print(llmAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dbd3f55-c8f3-468e-8d2b-64be141539fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"For how long should I take Kalachikai powder to overcome PCOD problem?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1280d8d6-8ff9-4117-b1a1-ba592451ff33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question, at the end of your response say thank you for your query.\n",
      "For how long should I take Kalachikai powder to overcome PCOD problem?\n",
      "\n",
      "LLM Answer:\n",
      "Hello. For PCOD (polycystic ovarian disease), powder Kalachikai has a good effect, but the duration of treatment is long (more than three months). For proper evaluation of disease, please go for USG\n"
     ]
    }
   ],
   "source": [
    "ask(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
